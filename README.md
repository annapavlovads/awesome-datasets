<div align="center">
  <h1>Awesome Datasets</h1>
</div>

We're collecting (an admittedly opinionated) public data sources in high quality. Most of the data sets listed below are free, however, some are not. They are classified by industry and use case.

*We're only at the beginning, and you can help by contributing to this GitHub!*

<!-- omit in toc -->
## How Can I Help?

If you're interested in this area and would like to hear more, join our [Slack community (coming soon)](#)! We'd also appreciate if you could fill out this short [form (coming soon)](#) to help us better understand what your interests might be.

<!-- omit in toc -->
### Feedback

If you have ideas on how we can make this repository better, feel free to submit an issue with suggestions.

<!-- omit in toc -->
### Contributing

We want this resource to grow with contributions from readers and data enthusiasts. If you'd like to make contributions to this Github repository, please read our contributing guidelines.

<!-- omit in toc -->
# Table of Content

- [Agriculture](#agriculture)
  - [Production](#production)
    - [Grading and sorting of produce](#grading-and-sorting-of-produce)
    - [Weed detection](#weed-detection)
    - [Crop health tracking](#crop-health-tracking)
    - [Crop maturity monitoring](#crop-maturity-monitoring)
    - [Soil health monitoring](#soil-health-monitoring)
  - [Livestock](#livestock)
    - [Animal counting](#animal-counting)
    - [Disease/Unusual behaviour detection](#diseaseunusual-behaviour-detection)
  - [Equipment](#equipment)
    - [Autonomous machines (e.g tractors)](#autonomous-machines-eg-tractors)
  - [Treatment](#treatment)
    - [Insect detection](#insect-detection)
    - [Intelligent fertilizing](#intelligent-fertilizing)
    - [Automatic weeding](#automatic-weeding)
    - [Intelligent spraying](#intelligent-spraying)
- [Automotive](#automotive)
  - [Sales](#sales)
    - [Advanced chatbot](#advanced-chatbot)
  - [Security](#security)
    - [In-cockpit driver’s behavior monitoring](#in-cockpit-drivers-behavior-monitoring)
  - [Maintenance](#maintenance)
    - [Vehicle maintenance recommendation](#vehicle-maintenance-recommendation)
  - [AD/ADAS](#adadas)
    - [On-road video analysis](#on-road-video-analysis)
    - [On-road point cloud / multi sensor fusion analysis](#on-road-point-cloud--multi-sensor-fusion-analysis)
  - [Operations](#operations)
    - [In-car voice assistant](#in-car-voice-assistant)
- [Banking](#banking)
  - [Compliance](#compliance)
    - [KYC/KYB automation](#kyckyb-automation)
    - [Fraud detection](#fraud-detection)
  - [Customer Service](#customer-service)
    - [Advanced chatbot](#advanced-chatbot-1)
    - [AI Voicebot](#ai-voicebot)
    - [Voice of Customer](#voice-of-customer)
  - [Operations](#operations-1)
    - [Complex document processing](#complex-document-processing)
      - [Compliance](#compliance-1)
      - [Legal](#legal)
      - [Customer process](#customer-process)
    - [Email classification](#email-classification)
    - [Financial Spreading automation](#financial-spreading-automation)
    - [Invoice processing](#invoice-processing)
- [Defense & Aerospace](#defense--aerospace)
  - [Aerospace](#aerospace)
    - [Autopilot of plane on the tarmac](#autopilot-of-plane-on-the-tarmac)
    - [Autopilot of plane during the flight](#autopilot-of-plane-during-the-flight)
    - [Augmented control tower](#augmented-control-tower)
    - [Earth observation and land composition analysis](#earth-observation-and-land-composition-analysis)
    - [Maneuver automatic recognition for flight test data analysis](#maneuver-automatic-recognition-for-flight-test-data-analysis)
  - [Surveillance](#surveillance)
    - [Object detection on image](#object-detection-on-image)
      - [Boat/Vessel detection](#boatvessel-detection)
      - [Flying object detection](#flying-object-detection)
      - [Boat/vessel detection](#boatvessel-detection-1)
      - [Aerial detection](#aerial-detection)
    - [Missile targeting (on-missile camera)](#missile-targeting-on-missile-camera)
    - [Missile targeting (on-plane/launcher camera)](#missile-targeting-on-planelauncher-camera)
    - [Object detection on video](#object-detection-on-video)
  - [Manufacturing](#manufacturing)
    - [Complex Document processing](#complex-document-processing-1)
      - [Compliance](#compliance-2)
      - [Knowledge management](#knowledge-management)
      - [Technical documentation](#technical-documentation)
      - [Quality report](#quality-report)
    - [Defect detection](#defect-detection)
    - [Visual inspection on infrastructure](#visual-inspection-on-infrastructure)
    - [Assisted maintenance (pre-filling of maintenance questionnaire)](#assisted-maintenance-pre-filling-of-maintenance-questionnaire)
- [Gaming, Media & Entertainment](#gaming-media--entertainment)
  - [Production](#production-1)
    - [Content Classification/ Recommandation](#content-classification-recommandation)
    - [Content Edition](#content-edition)
    - [Sport shot / footage live selection to broadcast](#sport-shot--footage-live-selection-to-broadcast)
    - [Subtitles generation](#subtitles-generation)
    - [Content creation](#content-creation)
  - [Marketing](#marketing)
    - [Audience / Reviews analysis](#audience--reviews-analysis)
  - [Advertisement](#advertisement)
    - [Hyper targeted advertising](#hyper-targeted-advertising)
    - [Hyper targeted personalization](#hyper-targeted-personalization)
  - [Moderation](#moderation)
    - [By image analysis](#by-image-analysis)
    - [Using NLP](#using-nlp)
    - [Toxic players identification using NLP](#toxic-players-identification-using-nlp)
    - [Toxic players identification using voice analysis](#toxic-players-identification-using-voice-analysis)
- [Healthcare](#healthcare)
  - [Research](#research)
    - [Pharmacovigilance](#pharmacovigilance)
    - [Medical records analysis to help diagnostic](#medical-records-analysis-to-help-diagnostic)
    - [Patient/doctors recruitment for clinical trials](#patientdoctors-recruitment-for-clinical-trials)
  - [Medical](#medical)
    - [Disease mention analysis on diagnostic documents](#disease-mention-analysis-on-diagnostic-documents)
    - [Mental Health support with chatbot](#mental-health-support-with-chatbot)
    - [Chatbot to provide medical information and suggest diagnostic](#chatbot-to-provide-medical-information-and-suggest-diagnostic)
    - [Digital Nurse (chatbot to provide care and track user’s health)](#digital-nurse-chatbot-to-provide-care-and-track-users-health)
    - [Bladder cancer detection](#bladder-cancer-detection)
    - [Dermatology scans for Melanoma detection](#dermatology-scans-for-melanoma-detection)
    - [AI-assisted X-Ray for pulmonary diseases](#ai-assisted-x-ray-for-pulmonary-diseases)
    - [Ophtalmology](#ophtalmology)
    - [Digital Pathology](#digital-pathology)
    - [CT and MRI scans analysis to assist Radiologists](#ct-and-mri-scans-analysis-to-assist-radiologists)
  - [Operations](#operations-2)
    - [Healthcare claims processing](#healthcare-claims-processing)
- [Insurance](#insurance)
  - [Claims](#claims)
    - [Damage estimate after accident](#damage-estimate-after-accident)
    - [Automated pay-outs calculation](#automated-pay-outs-calculation)
    - [Customer claims call analysis](#customer-claims-call-analysis)
    - [Damage estimate after Natural disasters](#damage-estimate-after-natural-disasters)
  - [Customer service](#customer-service-1)
    - [Advanced chatbot inc. policy estimate, claims process](#advanced-chatbot-inc-policy-estimate-claims-process)
    - [AI Voicebot](#ai-voicebot-1)
    - [Voice of Customer](#voice-of-customer-1)
  - [Compliance](#compliance-3)
    - [KYC/KYB automation](#kyckyb-automation-1)
    - [Fraud detection by Face Recognition](#fraud-detection-by-face-recognition)
    - [Fraud detection by abnormal behaviors recognition](#fraud-detection-by-abnormal-behaviors-recognition)
    - [Driver’s behavior analysis](#drivers-behavior-analysis)
  - [Operations](#operations-3)
    - [Complex Document processing](#complex-document-processing-2)
      - [Compliance & Legal](#compliance--legal)
      - [Customer processes](#customer-processes)
      - [Claims](#claims-1)
      - [Pre-authorizations](#pre-authorizations)
  - [Underwritting](#underwritting)
    - [Risk assessment with complementary aerial imagery](#risk-assessment-with-complementary-aerial-imagery)
    - [Level of exposition estimation in contracts](#level-of-exposition-estimation-in-contracts)
    - [Underwriting decision optimization](#underwriting-decision-optimization)
- [Manufacturing](#manufacturing-1)
  - [Production](#production-2)
    - [Bar-code reading](#bar-code-reading)
    - [Inventory monitoring](#inventory-monitoring)
    - [Wrong piece/material picking detection](#wrong-piecematerial-picking-detection)
    - [Worker’s gesture analysis to prevent mistake](#workers-gesture-analysis-to-prevent-mistake)
    - [Automated product assembly](#automated-product-assembly)
  - [Operations](#operations-4)
    - [Complex Document processing](#complex-document-processing-3)
      - [Contracts](#contracts)
      - [Customer processes](#customer-processes-1)
      - [Technical documentation](#technical-documentation-1)
      - [Quality report](#quality-report-1)
  - [Quality/Safety](#qualitysafety)
    - [Defect detection](#defect-detection-1)
    - [Visual inspection on infrastructure](#visual-inspection-on-infrastructure-1)
    - [Packaging quality monitoring](#packaging-quality-monitoring)
    - [Workers’ behavior monitoring to detect safety rules abidance](#workers-behavior-monitoring-to-detect-safety-rules-abidance)
    - [Packaging monitoring (correct contenance)](#packaging-monitoring-correct-contenance)
    - [Predictive maintenance](#predictive-maintenance)
- [Oil & Gas](#oil--gas)
  - [Safety](#safety)
    - [Fire detection](#fire-detection)
    - [Workers’ behavior monitoring to detect safety rules abidance](#workers-behavior-monitoring-to-detect-safety-rules-abidance-1)
  - [Exploitation](#exploitation)
    - [Geological assessment](#geological-assessment)
    - [Hydraulic fracturing analysis](#hydraulic-fracturing-analysis)
    - [Real Time drilling monitoring](#real-time-drilling-monitoring)
  - [Maintenance](#maintenance-1)
    - [Pipeline defect detection](#pipeline-defect-detection)
    - [Automatic recognition of analog instruments](#automatic-recognition-of-analog-instruments)
    - [Wireline spooling anomalies detection](#wireline-spooling-anomalies-detection)
    - [Corrosion detection](#corrosion-detection)
    - [Field workers assistance with voicebots](#field-workers-assistance-with-voicebots)
    - [Predictive analytics/maintenance](#predictive-analyticsmaintenance)
- [Railway](#railway)
  - [Research](#research-1)
    - [Defect and obstacle on railway detection](#defect-and-obstacle-on-railway-detection)
    - [Defect on machines detection (e.g train)](#defect-on-machines-detection-eg-train)
    - [Signalling detection](#signalling-detection)
    - [Passenger flux monitoring](#passenger-flux-monitoring)
    - [Dangerous behavior detection](#dangerous-behavior-detection)
  - [Operations](#operations-5)
    - [Technical questionnaire processing](#technical-questionnaire-processing)
- [Retail (e-commerce)](#retail-e-commerce)
  - [Recommendation](#recommendation)
    - [Make-up / cream recommendation from customer’s face picture](#make-up--cream-recommendation-from-customers-face-picture)
    - [Recommendation system improvement](#recommendation-system-improvement)
  - [Marketing](#marketing-1)
    - [Sentiment analysis of reviews / social medias / blogs](#sentiment-analysis-of-reviews--social-medias--blogs)
    - [Hyper targeted recommendation](#hyper-targeted-recommendation)
    - [Hyper targeted advertisement](#hyper-targeted-advertisement)
  - [Customer Service](#customer-service-2)
    - [Advanced chatbot](#advanced-chatbot-2)
  - [Sales](#sales-1)
    - [Counterfeit product detection](#counterfeit-product-detection)
    - [Search engine improvement](#search-engine-improvement)
    - [Virtual dressing rooms](#virtual-dressing-rooms)
  - [Production](#production-3)
    - [Product categorization from image](#product-categorization-from-image)
    - [Product search from voice search](#product-search-from-voice-search)
    - [Product search from image search](#product-search-from-image-search)
- [Retail (in-store)](#retail-in-store)
  - [Logistics](#logistics)
    - [Shelf management - Inventory status](#shelf-management---inventory-status)
    - [Shelf management - Quality monitoring](#shelf-management---quality-monitoring)
    - [Theft detection](#theft-detection)
  - [Sales](#sales-2)
    - [Automatic basket analysis](#automatic-basket-analysis)
    - [In-store tracking of customer’s placement and behaviors/purchase patterns](#in-store-tracking-of-customers-placement-and-behaviorspurchase-patterns)
    - [Virtual mirrors](#virtual-mirrors)
- [Security](#security-1)
  - [Surveillance](#surveillance-1)
    - [Access Control with Facial Recognition](#access-control-with-facial-recognition)
    - [Restricted area penetration detection](#restricted-area-penetration-detection)
    - [Theft detection](#theft-detection-1)
    - [Fire detection](#fire-detection-1)
    - [Crowd monitoring](#crowd-monitoring)
    - [Safety behavior compliance monitoring](#safety-behavior-compliance-monitoring)
    - [Targeted individuals identification with Facial Recognition](#targeted-individuals-identification-with-facial-recognition)
    - [Dangerous behaviors monitoring](#dangerous-behaviors-monitoring)
- [Tech](#tech)
  - [Augmented product intelligence with Automated document processing](#augmented-product-intelligence-with-automated-document-processing)
  - [Generalist document processing](#generalist-document-processing)
  - [Technical document processing](#technical-document-processing)
  - [Legal document processing](#legal-document-processing)
  - [Medical document processing](#medical-document-processing)
- [Telco](#telco)
  - [Operations](#operations-6)
    - [Complex Document processing](#complex-document-processing-4)
      - [Compliance](#compliance-4)
      - [Customer processes](#customer-processes-2)
      - [Email Processing](#email-processing)
      - [Technical documentation](#technical-documentation-2)
      - [Quality report](#quality-report-2)
  - [Customer Service](#customer-service-3)
    - [Advanced chatbot](#advanced-chatbot-3)
    - [Voice of Customer](#voice-of-customer-2)
  - [Regulatory](#regulatory)
    - [Consumption Fraud detection](#consumption-fraud-detection)
    - [Fraud detection by voice analysis](#fraud-detection-by-voice-analysis)
  - [Maintenance](#maintenance-2)
    - [Augmented technician](#augmented-technician)
    - [Visual inspection on infrastructure](#visual-inspection-on-infrastructure-2)
- [Utilities](#utilities)
  - [Customer Service](#customer-service-4)
    - [Advanced chatbot](#advanced-chatbot-4)
    - [Voice of Customer](#voice-of-customer-3)
  - [Engineering](#engineering)
    - [Technical drawing analysis](#technical-drawing-analysis)
  - [Fraud](#fraud)
    - [Consumption Fraud detection](#consumption-fraud-detection-1)
  - [Maintenance](#maintenance-3)
    - [Augmented technician](#augmented-technician-1)
    - [Vegetation inspection](#vegetation-inspection)
    - [Visual inspection on infrastructure](#visual-inspection-on-infrastructure-3)
  - [Operations](#operations-7)
    - [Complex Document processing](#complex-document-processing-5)
      - [Compliance](#compliance-5)
      - [Customer processes](#customer-processes-3)
      - [Technical documentation](#technical-documentation-3)
      - [Quality report](#quality-report-3)
    - [Email Processing](#email-processing-1)
  - [Safety](#safety-1)
    - [Wildfire detection](#wildfire-detection)
  - [Waste](#waste)
    - [Automated sorting of recyclables](#automated-sorting-of-recyclables)
    - [Intelligent bins](#intelligent-bins)


# Agriculture

## Production

### Grading and sorting of produce

### Weed detection

### Crop health tracking

### Crop maturity monitoring

### Soil health monitoring


## Livestock

### Animal counting

### Disease/Unusual behaviour detection


## Equipment

### Autonomous machines (e.g tractors)


## Treatment

### Insect detection

### Intelligent fertilizing

### Automatic weeding

### Intelligent spraying



# Automotive

## Sales

### Advanced chatbot

- See [Advanced chatbot](#advanced-chatbot-1) in Banking

## Security

### In-cockpit driver’s behavior monitoring


## Maintenance

### Vehicle maintenance recommendation


## AD/ADAS

### On-road video analysis

### On-road point cloud / multi sensor fusion analysis

## Operations

### In-car voice assistant


# Banking

## Compliance

### KYC/KYB automation

### Fraud detection


## Customer Service

### Advanced chatbot

Question-Answer Datasets for Chatbot Training

- [AmbigQA](https://nlp.cs.washington.edu/ambigqa/) is a new open-domain question answering task that consists of predicting a set of question and answer pairs, where each plausible answer is associated with a disambiguated rewriting of the original question. The data set covers 14,042 open-ended QI-open questions.

- [Break](https://allenai.github.io/Break/) is a set of data for understanding issues, aimed at training models to reason about complex issues. It consists of 83,978 natural language questions, annotated with a new meaning representation, the Question Decomposition Meaning Representation (QDMR). Each example includes the natural question and its QDMR representation.

- [CommonsenseQA](https://www.tau-nlp.org/commonsenseqa) is a set of multiple-choice question answer data that requires different types of common sense knowledge to predict the correct answers . It contains 12,102 questions with one correct answer and four distracting answers. The data set is provided in two main training/validation/test sets: "random assignment", which is the main evaluation assignment, and "question token assignment".

- [CoQA](https://stanfordnlp.github.io/coqa/) is a large-scale data set for the construction of conversational question answering systems. The CoQA contains 127,000 questions with answers, obtained from 8,000 conversations involving text passages from seven different domains.

- [DROP](https://allennlp.org/drop) is a 96-question repository, created by the opposing party, in which a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations on them (such as adding, counting or sorting). These operations require a much more complete understanding of paragraph content than was required for previous data sets.

- [DuReader 2.0](https://ai.baidu.com/broad/subordinate?dataset=dureader) is a large-scale, open-domain Chinese data set for reading comprehension (RK) and question answering (QA). It contains over 300K questions, 1.4M obvious documents and corresponding human-generated answers.

- [HotpotQA](https://hotpotqa.github.io/) is a set of question response data that includes natural multi-skip questions, with a strong emphasis on supporting facts to allow for more explicit question answering systems. The data set consists of 113,000 Wikipedia-based QA pairs.

- [NarrativeQA](https://github.com/deepmind/narrativeqa) is a data set constructed to encourage deeper understanding of language. This dataset involves reasoning about reading whole books or movie scripts. This dataset contains approximately 45,000 pairs of free text question-and-answer pairs. There are two modes of understanding this dataset: (1) reading comprehension on summaries and (2) reading comprehension on whole books/scripts.

- [Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions), a new large-scale corpus for training and evaluating open-ended question answering systems, and the first to replicate the end-to-end process in which people find answers to questions. NQ is a large corpus, consisting of 300,000 questions of natural origin, as well as human-annotated answers from Wikipedia pages, for use in training in quality assurance systems. In addition, we have included 16,000 examples where the answers (to the same questions) are provided by 5 different annotators, useful for evaluating the performance of the QA systems learned.

- The objective of the [NewsQA](https://www.microsoft.com/en-us/research/project/newsqa-dataset) dataset is to help the research community build algorithms capable of answering questions that require human-scale understanding and reasoning skills. Based on CNN articles from the DeepMind Q&A database, we have prepared a Reading Comprehension dataset of 120,000 pairs of questions and answers.

- [OpenBookQA](https://github.com/allenai/OpenBookQA), inspired by open-book exams to assess human understanding of a subject. The open book that accompanies our questions is a set of 1329 elementary level scientific facts. Approximately 6,000 questions focus on understanding these facts and applying them to new situations.

- [QASC](https://github.com/allenai/qasc) is a question-and-answer data set that focuses on sentence composition. It consists of 9,980 8-channel multiple-choice questions on elementary school science (8,134 train, 926 dev, 920 test), and is accompanied by a corpus of 17M sentences.

- [QuAC](https://quac.ai/), a data set for answering questions in context that contains 14K information-seeking QI dialogues (100K questions in total). Question Answering in Context is a dataset for modeling, understanding, and participating in information-seeking dialogues. The data instances consist of an interactive dialogue between two crowd workers: (1) a student who asks a sequence of free questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts (staves) of the text. QuAC introduces challenges not found in existing machine comprehension data sets: its questions are often more open-ended, unanswered, or only meaningful in the context of dialogue.

- [Question-and-answer dataset](https://www.cs.cmu.edu/~ark/QA-data/): This corpus includes Wikipedia articles, factual questions manually generated from them, and answers to these manually generated questions for use in academic research.

- A set of [Quora questions](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs) to determine whether pairs of question texts actually correspond to semantically equivalent queries. More than 400,000 lines of potential questions duplicate question pairs.

- [RecipeQA](https://hucvl.github.io/recipeqa/) is a set of data for multimodal understanding of recipes. It consists of more than 36,000 pairs of automatically generated questions and answers from approximately 20,000 unique recipes with step-by-step instructions and images. Each RecipeQA question involves multiple modalities such as titles, descriptions or images, and working towards an answer requires (i) a common understanding of images and text, (ii) capturing the temporal flow of events, and (iii) understanding procedural knowledge.

- [The Stanford Question Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer/) is a set of reading comprehension data consisting of questions asked by social workers on a set of Wikipedia articles, where the answer to each question is a segment of text, or span, of the corresponding reading passage. With more than 100,000 question-answer pairs on more than 500 articles, SQuAD is significantly larger than previous reading comprehension datasets. SQuAD2.0 combines the 100,000 questions from SQuAD1.1 with more than 50,000 new unanswered questions written in a contradictory manner by crowd workers to look like answered questions.

- [TREC QA Collection](https://trec.nist.gov/data/qa.html): TREC has had a track record of answering questions since 1999. In each track, the task was defined so that systems had to retrieve small fragments of text containing an answer to open-domain and closed-domain questions.

- [TyDi QA](https://github.com/google-research-datasets/tydiqa) is a set of question response data covering 11 typologically diverse languages with 204K question-answer pairs. The languages in TyDi QA are diverse in terms of their typology -- the set of linguistic characteristics that each language expresses -- so we expect that the models performing on this set will be generalizable to a large number of languages around the world. It contains linguistic phenomena that would not be found in English-only corpora.

- [The WikiQA corpus](http://research.microsoft.com/apps/mobile/download.aspx?p=4495da01-db8c-4041-a7f6-7984a4f6a905): A set of publicly available pairs of questions and phrases collected and annotated for research on the answer to open-domain questions. In order to reflect the true information needs of general users, they used Bing query logs as a source of questions. Each question is linked to a Wikipedia page that potentially contains the answer.

- [Yahoo Language Data](https://webscope.sandbox.yahoo.com/catalog.php?datatype=l): This page presents manually maintained QA datasets from Yahoo responses.

Customer Support Datasets for Chatbot Training

- [Customer Support on Twitter](https://www.kaggle.com/thoughtvector/customer-support-on-twitter): This Kaggle dataset includes more than 3 million tweets and responses from leading brands on Twitter.

- [Relational Strategies in Customer Service Dataset](https://s3-us-west-2.amazonaws.com/nextit-public/cl2017data.html): A dataset of travel-related customer service data from four sources. Conversation logs from three commercial customer service VIAs and airline forums on TripAdvisor.com during the month of August 2016.

- [Ubuntu Dialogue Corpus](https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus): Consists of nearly one million two-person conversations from Ubuntu discussion logs, used to receive technical support for various Ubuntu-related issues. The dataset contains 930,000 dialogs and over 100,000,000 words.

Dialogue Datasets for Chatbot Training

- [A data set of 502 dialogues](https://ai.google/tools/datasets/coached-conversational-preference-elicitation) with 12,000 annotated statements between a user and a wizard discussing natural language movie preferences. The data were collected using the Oz Assistant method between two paid workers, one of whom acts as an "assistant" and the other as a "user".

- [ConvAI2 dataset](http://convai.io/data): The dataset contains more than 2000 dialogs for a PersonaChat contest, where human evaluators recruited through the Yandex.Toloka crowdsourcing platform chatted with bots submitted by teams.

- [Cornell Movie-Dialogs Corpus](http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html): This corpus contains an extensive collection of metadata-rich fictional conversations extracted from raw movie scripts: 220,579 conversational exchanges between 10,292 movie character pairs involving 9,035 characters from 617 movies.

- [Maluuba goal-oriented dialogue](https://datasets.maluuba.com/Frames): A set of open dialogue data where the conversation is aimed at accomplishing a task or making a decision - in particular, finding flights and a hotel. The data set contains complex conversations and decisions covering over 250 hotels, flights and destinations.

- [Multi-Domain Wizard-of-Oz dataset (MultiWOZ)](http://dialogue.mi.eng.cam.ac.uk/index.php/corpus/): A comprehensive collection of written conversations covering multiple domains and topics. The dataset contains 10,000 dialogs, and is at least an order of magnitude larger than any previous task-oriented annotated corpus.

- [The NPS Chat Corpus](http://faculty.nps.edu/cmartell/NPSChat.htm): This corpus consists of 10,567 messages out of approximately 500,000 messages collected from various online chat services in accordance with their terms of service.

- [Santa Barbara Corpus of Spoken American English](http://www.linguistics.ucsb.edu/research/santa-barbara-corpus): This dataset contains approximately 249,000 words of transcription, audio and timestamp at the individual intonation units.

- [SGD (Schema-Guided Dialogue) dataset](https://github.com/google-research-datasets/dstc8-schema-guided-dialogue), containing over 16k of multi-domain conversations covering 16 domains. Our dataset exceeds the size of existing task-oriented dialog corpora, while highlighting the challenges of creating large-scale virtual wizards. It provides a challenging test bed for a number of tasks, including language comprehension, slot filling, dialog status monitoring, and response generation.

- [Semantic Web IRC Chat Logs Interest Group](http://chatlogs.planetrdf.com/swig/): This automatically generated IRC chat log is available in RDF, since 2004, on a daily basis, including timestamps and nicknames.

Multilingual Datasets for Chatbot Training

- [EXCITEMENTS datasets](https://github.com/hltfbk/EOP-1.2.1/wiki/Data-Sets#data-sets-that-have-to-be-downloaded-separately): These datasets, available in English and Italian, contain negative comments from customers giving reasons for their dissatisfaction with a given company.

- [NUS Corpus](http://wing.comp.nus.edu.sg:8080/SMSCorpus/history.jsp): This corpus was created for the standardization and translation of social media texts. It is built by randomly selecting 2,000 messages from the NUS corpus of SMS in English and then translating them into formal Chinese.

- [OPUS](http://opus.nlpl.eu/) is a growing collection of translated texts from the web. In the OPUS project they try to convert and align free online data, to add linguistic annotation, and to provide the community with a publicly available parallel corpus. It contains dialog datasets as well as other types of datasets.


### AI Voicebot 


### Voice of Customer


## Operations

### Complex document processing

#### Compliance

#### Legal

#### Customer process


### Email classification

- [Enron Email Dataset](https://www.cs.cmu.edu/~./enron/) This dataset was collected and prepared by the CALO Project (A Cognitive Assistant that Learns and Organizes). It contains data from about 150 users, mostly senior management of Enron, organized into folders. The corpus contains a total of about 0.5M messages. This data was originally made public, and posted to the web, by the Federal Energy Regulatory Commission during its investigation. 
- [UC Berkeley Enron Email Analysis](https://bailando.berkeley.edu/enron_email.html) A categorized version of the Enron Email Dataset. Main topics are: coarse genre, included/forwarded information, primary topics, and emotional tone.

### Financial Spreading automation

### Invoice processing

- [The RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/) The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images. The images are sized so their largest dimension does not exceed 1000 pixels.

# Defense & Aerospace

## Aerospace

### Autopilot of plane on the tarmac

### Autopilot of plane during the flight

### Augmented control tower

### Earth observation and land composition analysis

### Maneuver automatic recognition for flight test data analysis


## Surveillance

### Object detection on image

#### Boat/Vessel detection

#### Flying object detection

#### Boat/vessel detection

#### Aerial detection

### Missile targeting (on-missile camera)

### Missile targeting (on-plane/launcher camera)

### Object detection on video


## Manufacturing

### Complex Document processing

- [The RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/) The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images. The images are sized so their largest dimension does not exceed 1000 pixels.

#### Compliance

#### Knowledge management

#### Technical documentation

#### Quality report

### Defect detection

### Visual inspection on infrastructure

### Assisted maintenance (pre-filling of maintenance questionnaire)



# Gaming, Media & Entertainment

## Production

### Content Classification/ Recommandation

### Content Edition

### Sport shot / footage live selection to broadcast

### Subtitles generation

### Content creation

## Marketing

### Audience / Reviews analysis


## Advertisement

### Hyper targeted advertising

### Hyper targeted personalization 


## Moderation

### By image analysis

### Using NLP

### Toxic players identification using NLP

### Toxic players identification using voice analysis



# Healthcare

## Research

### Pharmacovigilance

### Medical records analysis to help diagnostic

### Patient/doctors recruitment for clinical trials 


## Medical

### Disease mention analysis on diagnostic documents 

### Mental Health support with chatbot

### Chatbot to provide medical information and suggest diagnostic

### Digital Nurse (chatbot to provide care and track user’s health)

### Bladder cancer detection

### Dermatology scans for Melanoma detection

### AI-assisted X-Ray for pulmonary diseases

### Ophtalmology

### Digital Pathology

### CT and MRI scans analysis to assist Radiologists


## Operations

### Healthcare claims processing


# Insurance

## Claims

### Damage estimate after accident 

### Automated pay-outs calculation

### Customer claims call analysis

### Damage estimate after Natural disasters



## Customer service

### Advanced chatbot inc. policy estimate, claims process

- See [Advanced chatbot](#advanced-chatbot-1) in Banking

### AI Voicebot 

### Voice of Customer


## Compliance

### KYC/KYB automation 

### Fraud detection by Face Recognition

### Fraud detection by abnormal behaviors recognition

### Driver’s behavior analysis


## Operations

### Complex Document processing

- [The RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/) The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images. The images are sized so their largest dimension does not exceed 1000 pixels.

#### Compliance & Legal

#### Customer processes

#### Claims

#### Pre-authorizations


## Underwritting

### Risk assessment with complementary aerial imagery

### Level of exposition estimation in contracts

### Underwriting decision optimization


# Manufacturing

## Production

### Bar-code reading

### Inventory monitoring

### Wrong piece/material picking detection

### Worker’s gesture analysis to prevent mistake

### Automated product assembly


## Operations

### Complex Document processing

- [The RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/) The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images. The images are sized so their largest dimension does not exceed 1000 pixels.

#### Contracts

#### Customer processes

#### Technical documentation

#### Quality report

## Quality/Safety

### Defect detection

- [Severstal: Steel Defect Detection](https://www.kaggle.com/c/severstal-steel-defect-detection) This dataset if about localizing and classifying surface defects on a steel sheet.

### Visual inspection on infrastructure

### Packaging quality monitoring

### Workers’ behavior monitoring to detect safety rules abidance 

### Packaging monitoring (correct contenance)

### Predictive maintenance



# Oil & Gas

## Safety

### Fire detection

- [The FLAME dataset](https://ieee-dataport.org/open-access/flame-dataset-aerial-imagery-pile-burn-detection-using-drones-uavs) This dataset consists of different repositories including raw aerial videos recorded by drones' cameras and also raw heatmap footage recorded by an infrared thermal camera.
- [FireNET](https://github.com/OlafenwaMoses/FireNET) - approx. 500 fire images with bounding boxes in pascal voc XML format. Repo contains trained Yolo3 model trained using [imageai](https://github.com/OlafenwaMoses/ImageAI), unknown performance. However small images, 275x183 pixels on average, meaning there are fewer textural features for a network to learn.
- [Fire Detection from CCTV on Kaggle](https://www.kaggle.com/ritupande/fire-detection-from-cctv) - images and video, images are extracted from video, relatively small dataset with all images only taken from 3-4 videos. Quite relevant to current task as have videos to test on. Dataset organised for classification task of normal/smoke/fire, no bounding box annotations
- [cair/Fire-Detection-Image-Dataset](https://github.com/cair/Fire-Detection-Image-Dataset) - This dataset contains many normal images and 111 images with fire. Dataset is highly unbalanced to reciprocate real world situations. Images are decent size but not annotated.
- [mivia Fire Detection Dataset](https://mivia.unisa.it/datasets/video-analysis-datasets/fire-detection-dataset/) - approx. 30 videos
- [USTC smoke detection](http://smoke.ustc.edu.cn/datasets.htm) - links to various sources that provide videos of smoke
- fire/not-fire dataset in the pyimagesearch article can be downloaded. Note that there are many images of fire scenes that do not contain actual fire, but burnt out homes for example.
- [FIRE Dataset on Kaggle](https://www.kaggle.com/phylake1337/fire-dataset) - 755 outdoor fire images and 244 non-fire images. Images are decent size but not annotated
- [Fire Image Data Set for Dunnings 2018 study](https://collections.durham.ac.uk/files/r2d217qp536#.X2rv1ZNKidb) - PNG still image set
- [Fire Superpixel Image Data Set for Samarth 2019 study](https://collections.durham.ac.uk/files/r10r967374q#.X2rv1pNKidb) - PNG still image set
- [Wildfire Smoke Dataset](https://public.roboflow.com/object-detection/wildfire-smoke) - 737 annotated (bounding boxed) images
- [Dataset by jackfrost1411](https://github.com/jackfrost1411/fire-detection) -> several hundred images sorted into fire/neutral for classification task. No bounding box annotations
- [fire-and-smoke-dataset on Kaggle](https://www.kaggle.com/dataclusterlabs/fire-and-smoke-dataset) -> 7000+ images, consisting of 691 flame only images, 3721 smoke only images, and 4207 fire {flame & smoke} images
- [Domestic-Fire-and-Smoke-Dataset](https://github.com/datacluster-labs/Domestic-Fire-and-Smoke-Dataset) -> Approx. 5000 unique images, 2-class (fire and smoke), bounding box annotation, COCO, PASCAL VOC and YOLO formats
- [kaggle fire-and-gun-dataset](https://www.kaggle.com/atulyakumar98/fire-and-gun-dataset)

### Workers’ behavior monitoring to detect safety rules abidance 


## Exploitation

### Geological assessment

### Hydraulic fracturing analysis

### Real Time drilling monitoring


## Maintenance

### Pipeline defect detection

### Automatic recognition of analog instruments

### Wireline spooling anomalies detection

### Corrosion detection

### Field workers assistance with voicebots

### Predictive analytics/maintenance


# Railway

## Research

### Defect and obstacle on railway detection

### Defect on machines detection (e.g train)

### Signalling detection

### Passenger flux monitoring

### Dangerous behavior detection


## Operations

### Technical questionnaire processing


# Retail (e-commerce)

## Recommendation

### Make-up / cream recommendation from customer’s face picture

### Recommendation system improvement 


## Marketing

### Sentiment analysis of reviews / social medias / blogs

### Hyper targeted recommendation

### Hyper targeted advertisement


## Customer Service

### Advanced chatbot

- See [Advanced chatbot](#advanced-chatbot-1) in Banking

## Sales

### Counterfeit product detection

### Search engine improvement 

### Virtual dressing rooms



## Production

### Product categorization from image

### Product search from voice search

### Product search from image search



# Retail (in-store)

## Logistics

### Shelf management - Inventory status

### Shelf management - Quality monitoring

### Theft detection

## Sales

### Automatic basket analysis

### In-store tracking of customer’s placement and behaviors/purchase patterns

### Virtual mirrors


# Security

## Surveillance

### Access Control with Facial Recognition

### Restricted area penetration detection

### Theft detection

### Fire detection

### Crowd monitoring

### Safety behavior compliance monitoring

### Targeted individuals identification with Facial Recognition

### Dangerous behaviors monitoring



# Tech

## Augmented product intelligence with Automated document processing

## Generalist document processing 

## Technical document processing 

## Legal document processing 

## Medical document processing 


# Telco

## Operations

### Complex Document processing

- [The RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/) The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images. The images are sized so their largest dimension does not exceed 1000 pixels.

#### Compliance

#### Customer processes

#### Email Processing

#### Technical documentation

#### Quality report

## Customer Service

### Advanced chatbot

- See [Advanced chatbot](#advanced-chatbot-1) in Banking

### Voice of Customer


## Regulatory

### Consumption Fraud detection

### Fraud detection by voice analysis



## Maintenance

### Augmented technician

### Visual inspection on infrastructure


# Utilities

## Customer Service

### Advanced chatbot

- See [Advanced chatbot](#advanced-chatbot-1) in Banking

### Voice of Customer

## Engineering

### Technical drawing analysis

## Fraud

### Consumption Fraud detection


## Maintenance

### Augmented technician

### Vegetation inspection

### Visual inspection on infrastructure


## Operations

### Complex Document processing

- [The RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/) The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images. The images are sized so their largest dimension does not exceed 1000 pixels.

#### Compliance

#### Customer processes

#### Technical documentation

#### Quality report

### Email Processing

## Safety

### Wildfire detection 

- [1.88 Million US Wildfires](https://www.kaggle.com/datasets/rtatman/188-million-us-wildfires) This data publication contains a spatial database of wildfires that occurred in the United States from 1992 to 2015. It is the third update of a publication originally generated to support the national Fire Program Analysis (FPA) system. The wildfire records were acquired from the reporting systems of federal, state, and local fire organizations. The following core data elements were required for records to be included in this data publication: discovery date, final fire size, and a point location at least as precise as Public Land Survey System (PLSS) section (1-square mile grid). The data were transformed to conform, when possible, to the data standards of the National Wildfire Coordinating Group (NWCG). Basic error-checking was performed and redundant records were identified and removed, to the degree possible. The resulting product, referred to as the Fire Program Analysis fire-occurrence database (FPA FOD), includes 1.88 million geo-referenced wildfire records, representing a total of 140 million acres burned during the 24-year period.

## Waste

### Automated sorting of recyclables

### Intelligent bins



